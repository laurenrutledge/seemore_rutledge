# ----------------------------
# File: default.yaml
# ----------------------------
# ----------------------------
# ----------------------------


# ----------------------------
# Device Run Metadata
# ----------------------------
run_name: seemore_debug              # Name of this training run (used in logs, checkpoints)
device: cpu                         # "cuda" for GPU, or "cpu"



# ----------------------------
# Model Info - Taken from Google Collab
# ----------------------------

vocab_size: 100                      # Size of the output vocabulary
num_blks: 3                          # The number of encoder (ViT) transformer blocks
n_embd: 128                          # Decoder Token embedding Size
n_head: 8                            # Number of attention heads in decoder
n_layer: 8                           # Number of decoder blocks (/layers)
dropout: 0.1                         # The Drop-out rate in modeuls (given to us)
img_size: 96                         #  Input image resolution (which is square)
patch_size: 16                       #  Patch Size for the ViT
image_embed_dim: 512                 #  The Output dimension of the image encoder


# ----------------------------
# Training Settings
# ----------------------------
batch_size: 5                       # Batch Size for training
learning_rate: 1e-4                 # Initial Learning Rate (for AdamW from blog post)
weight_decay: 0.01                  # Regularization / weighted (L2)
num_epochs: 10                       # Total number of training epochs (trials)
log_interval: 10                    # The number of steps taken between each log of the training loss

distributed: false
use_amp: false